{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_experiments.ipynb","provenance":[],"collapsed_sections":["8gGkRjVGY1AS","T45jOiGUY1AT","uEb7JKKaXszU","CCKT0oL4DhVe","Tk1awUT-eXIC","DG-vpx1SmnO_","KpJJd-4JmnPD","o3Q4Kr2siDYA","5Px8Oug-Y_sO","KJImwF75iDYM","v6iYWRpdn79w","nhVCC9vupVUO"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9ae9c0e35709428aa0c0ec494d1aee7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9223a84cff27447d9a6f08e8c88c2c75","IPY_MODEL_41bc6b713ae44e058745e953b75031a6","IPY_MODEL_1073db19a3c64657a38d080d97b7b9b1"],"layout":"IPY_MODEL_afbaec7ac27e4876a7cdfee0185be42e"}},"9223a84cff27447d9a6f08e8c88c2c75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84fa6d177d284603b8ad8ed01d22c97b","placeholder":"​","style":"IPY_MODEL_e3fdce06f795496c8821ef931bee478e","value":"Downloading: 100%"}},"41bc6b713ae44e058745e953b75031a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c3f04415e594d25ae36c6fc3b504e0d","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0ef2631748942a1b16398903291a7fb","value":231508}},"1073db19a3c64657a38d080d97b7b9b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb7534d14195476bae6bb3112d85f4be","placeholder":"​","style":"IPY_MODEL_b7bfd7188e0e431e8915d29b67f86bfc","value":" 226k/226k [00:00&lt;00:00, 327kB/s]"}},"afbaec7ac27e4876a7cdfee0185be42e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84fa6d177d284603b8ad8ed01d22c97b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3fdce06f795496c8821ef931bee478e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c3f04415e594d25ae36c6fc3b504e0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0ef2631748942a1b16398903291a7fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb7534d14195476bae6bb3112d85f4be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7bfd7188e0e431e8915d29b67f86bfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb16d06535b748079ca1b24eb49ab8ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84296f9c0ca6458a8eecd9b6e31de92a","IPY_MODEL_ac8bd49ad5724d47b130f32b2f110edf","IPY_MODEL_b285ab978b254a5f86d8875b4c0d49c2"],"layout":"IPY_MODEL_72a587584922459295875e54c731b60c"}},"84296f9c0ca6458a8eecd9b6e31de92a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53df01d0b9cb421c8b6fbbf3e4c46e4b","placeholder":"​","style":"IPY_MODEL_60a327490e6e46808823e50870191fab","value":"Downloading: 100%"}},"ac8bd49ad5724d47b130f32b2f110edf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16211d7402b34fe9840ca04ec596d75c","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2739c56925fc491ba9893a08fd800a57","value":28}},"b285ab978b254a5f86d8875b4c0d49c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_205de3515ee94f9880993c8dcac28efc","placeholder":"​","style":"IPY_MODEL_b1fe2d8336cc4ecc830cac4285032cef","value":" 28.0/28.0 [00:00&lt;00:00, 605B/s]"}},"72a587584922459295875e54c731b60c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53df01d0b9cb421c8b6fbbf3e4c46e4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60a327490e6e46808823e50870191fab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16211d7402b34fe9840ca04ec596d75c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2739c56925fc491ba9893a08fd800a57":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"205de3515ee94f9880993c8dcac28efc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1fe2d8336cc4ecc830cac4285032cef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62af8cf8e61b497bbfe4b30c88ac6e83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85dce318d5ea4cba9839f1a876239819","IPY_MODEL_1831e9e99a1b4e3cad54193728ddf0e6","IPY_MODEL_b360a3312db441fcb769b5937e6234cd"],"layout":"IPY_MODEL_f8cf1a49ff514910bb6ccb762c922bb9"}},"85dce318d5ea4cba9839f1a876239819":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41fcac82b36244eb957c63b489ac5ab7","placeholder":"​","style":"IPY_MODEL_c0817f8ea75d4db28f84a715fd22fe4b","value":"Downloading: 100%"}},"1831e9e99a1b4e3cad54193728ddf0e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f0bb0abba39415facc2dd4640a19696","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2a2d21b1660437f9893998fd5e581ea","value":483}},"b360a3312db441fcb769b5937e6234cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0dc68046d7d449d90b74bfaba003591","placeholder":"​","style":"IPY_MODEL_0bb464662a214d2b98882541ee9b7a87","value":" 483/483 [00:00&lt;00:00, 3.25kB/s]"}},"f8cf1a49ff514910bb6ccb762c922bb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41fcac82b36244eb957c63b489ac5ab7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0817f8ea75d4db28f84a715fd22fe4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f0bb0abba39415facc2dd4640a19696":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2a2d21b1660437f9893998fd5e581ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0dc68046d7d449d90b74bfaba003591":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bb464662a214d2b98882541ee9b7a87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29a78ccd9dd14895a587c42ff3aac786":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca270cfda0ad4cddbe92afd65e3745c5","IPY_MODEL_c0ef30920a514e02b600edb4c8d9b3b2","IPY_MODEL_f9759b3a1fd1456b878cec3ff11dbccf"],"layout":"IPY_MODEL_566da2c42fe342b1945615f846cef3ab"}},"ca270cfda0ad4cddbe92afd65e3745c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fef3189dedce407db4b808bd42353c38","placeholder":"​","style":"IPY_MODEL_69acaac971f54c1ea0b09462433b7f88","value":"Downloading: 100%"}},"c0ef30920a514e02b600edb4c8d9b3b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84a156b118314c888e4fbc3043d54066","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d0ab482a11c40bd8788c633b462ec00","value":267967963}},"f9759b3a1fd1456b878cec3ff11dbccf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fff605336794c63a862db718fa71866","placeholder":"​","style":"IPY_MODEL_d4e4eafc3a1f4ab08f1962ffe23e72b2","value":" 256M/256M [00:14&lt;00:00, 17.1MB/s]"}},"566da2c42fe342b1945615f846cef3ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fef3189dedce407db4b808bd42353c38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69acaac971f54c1ea0b09462433b7f88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84a156b118314c888e4fbc3043d54066":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d0ab482a11c40bd8788c633b462ec00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fff605336794c63a862db718fa71866":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4e4eafc3a1f4ab08f1962ffe23e72b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b24c47da72a74a2591a1f6450ee0561f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9be991286be4d10a65ff603f92c7efe","IPY_MODEL_47df2fc7ea01440b9b5ec73dd0a05772","IPY_MODEL_42a5f0dc53804857a8a8a45b02c5de0c"],"layout":"IPY_MODEL_9ea997c5d77248f1af38aa676ea4b924"}},"c9be991286be4d10a65ff603f92c7efe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee120579b2b744ed8e6878a946cfb7fe","placeholder":"​","style":"IPY_MODEL_838c9ef4fbb840e396022f1dc70e271f","value":"Downloading: 100%"}},"47df2fc7ea01440b9b5ec73dd0a05772":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9d570bd7ee34727b1bbe7b72b3c055f","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a8d160143694e8993f7042fbe1f9ff7","value":231508}},"42a5f0dc53804857a8a8a45b02c5de0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58cbc6f90bef4a368c6ac5e8dd60fad1","placeholder":"​","style":"IPY_MODEL_ffadf5eb968c4d3a88480e166805787f","value":" 226k/226k [00:00&lt;00:00, 268kB/s]"}},"9ea997c5d77248f1af38aa676ea4b924":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee120579b2b744ed8e6878a946cfb7fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"838c9ef4fbb840e396022f1dc70e271f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9d570bd7ee34727b1bbe7b72b3c055f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a8d160143694e8993f7042fbe1f9ff7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58cbc6f90bef4a368c6ac5e8dd60fad1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffadf5eb968c4d3a88480e166805787f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd38a46b741b40778fc6b16593fcf7cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50bc6fbd39144daaba1a2b2f78f758dc","IPY_MODEL_1529288b8ade4a9aa384c7f11231e586","IPY_MODEL_d252bece78114029a0cbef50a0253481"],"layout":"IPY_MODEL_569aed5ab2614e6b88ae196f464ae44d"}},"50bc6fbd39144daaba1a2b2f78f758dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cfd898281464f4a926e4a397b7488a3","placeholder":"​","style":"IPY_MODEL_be5a256747184fc9ac934adb7d249621","value":"Downloading: 100%"}},"1529288b8ade4a9aa384c7f11231e586":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4251af3e3e54446cbbf2e296e4794773","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e3b2c75a08743f98c7d5f7249e89ded","value":28}},"d252bece78114029a0cbef50a0253481":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f35036c131b454c96c129af61fbd2e2","placeholder":"​","style":"IPY_MODEL_312e0a70b180469f8264d698111c6388","value":" 28.0/28.0 [00:00&lt;00:00, 650B/s]"}},"569aed5ab2614e6b88ae196f464ae44d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cfd898281464f4a926e4a397b7488a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be5a256747184fc9ac934adb7d249621":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4251af3e3e54446cbbf2e296e4794773":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e3b2c75a08743f98c7d5f7249e89ded":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f35036c131b454c96c129af61fbd2e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"312e0a70b180469f8264d698111c6388":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fa3d6b17fab4de7bec58c255833f005":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa16863c7ac649c387cc953d8dd9ee5a","IPY_MODEL_922c9edf56fb4706ad857295e81bc776","IPY_MODEL_3c8eb825b33b4ed0a3d7e39652bb125e"],"layout":"IPY_MODEL_faeafbb5fc8e4ecf9b1510e6041032cd"}},"aa16863c7ac649c387cc953d8dd9ee5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6812f3638d124c2e9d1d86b0cf9dd775","placeholder":"​","style":"IPY_MODEL_8899b635ee5f4cf295e7765a995b4f09","value":"Downloading: 100%"}},"922c9edf56fb4706ad857295e81bc776":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39f5c769d5c8482db88f0287dce8496d","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a77ca2d78c2c43ba9e1bf9df810c77f4","value":483}},"3c8eb825b33b4ed0a3d7e39652bb125e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0ea101a47784052a716cd55d2dfca83","placeholder":"​","style":"IPY_MODEL_008362e67af745ebbf550b044dc2ad33","value":" 483/483 [00:00&lt;00:00, 10.3kB/s]"}},"faeafbb5fc8e4ecf9b1510e6041032cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6812f3638d124c2e9d1d86b0cf9dd775":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8899b635ee5f4cf295e7765a995b4f09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39f5c769d5c8482db88f0287dce8496d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a77ca2d78c2c43ba9e1bf9df810c77f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0ea101a47784052a716cd55d2dfca83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"008362e67af745ebbf550b044dc2ad33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"DIqSUU-ZyQOX"}},{"cell_type":"code","source":["%%capture\n","!pip install transformers"],"metadata":{"id":"UXZ6vXTxtP1r"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"byIdshb9-Uky","executionInfo":{"status":"ok","timestamp":1649957137959,"user_tz":-480,"elapsed":91995,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"56f23d45-f0b8-46fc-8365-d456af0ef85a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n","import torch.utils.data as data_utils\n","import torch.optim as optim\n","import gc #garbage collector for gpu memory \n","from tqdm import tqdm\n","import json\n","import datetime as dt\n","\n","from transformers import BertForSequenceClassification, BertTokenizer, DistilBertModel, DistilBertTokenizer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoConfig, AutoModel\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","from google.colab import drive\n","from google.colab import files\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","source":["# Loading Data"],"metadata":{"id":"yuFqHudayb_3"}},{"cell_type":"code","source":["politifact_data = json.load(open(\"gdrive/MyDrive/BT4222/Data/politifact_clean.json\", \"r\"))\n","gossipcop_data = json.load(open(\"gdrive/MyDrive/BT4222/Data/gossipcop_clean.json\", \"r\"))\n","\n","# Convert list of json objects to dataframe\n","politifact_df = pd.DataFrame(politifact_data)\n","gossipcop_df = pd.DataFrame(gossipcop_data)\n","\n","# Conver labels to integers\n","politifact_df['target'] = politifact_df['label'].apply(lambda x: 1 if x=='real' else 0)\n","gossipcop_df['target'] = gossipcop_df['label'].apply(lambda x: 1 if x=='real' else 0)\n","\n","politifact_df['is_pf'] = 1\n","gossipcop_df['is_pf'] = 0\n","\n","concat_df = pd.concat([politifact_df,gossipcop_df])"],"metadata":{"id":"fQJpWF7Ytaif"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yRNBaK9Ra5rJ"},"outputs":[],"source":["politifact_df['parsed_month'] = politifact_df['publish_date'].apply(lambda x: dt.datetime.fromtimestamp(x).strftime(\"%m\") if not pd.isna(x) else '0')\n","gossipcop_df['parsed_month'] = gossipcop_df['publish_date'].apply(lambda x: dt.datetime.fromtimestamp(x).strftime(\"%m\") if not pd.isna(x) else '0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1DVuc4tLUtdw"},"outputs":[],"source":["politifact_df['parsed_hour'] = politifact_df['publish_date'].apply(lambda x: dt.datetime.fromtimestamp(x).strftime(\"%H\") if not pd.isna(x) else '0')\n","gossipcop_df['parsed_hour'] = gossipcop_df['publish_date'].apply(lambda x: dt.datetime.fromtimestamp(x).strftime(\"%H\") if not pd.isna(x) else '0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jpYIXt-D1HCK"},"outputs":[],"source":["politifact_df['publisher'] = politifact_df['publisher'].fillna('None')\n","gossipcop_df['publisher'] = gossipcop_df['publisher'].fillna('None')"]},{"cell_type":"code","source":["article = 'gossipcop'"],"metadata":{"id":"cRCKq2puXeso"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fdaaxfsRWDYt"},"source":["### Processing Other Features\n","\n","We shall one hot encode hour, month and publisher. Fill publisher NaN with None text."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHbQbiAg0XIL"},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder"]},{"cell_type":"code","source":["if article == \"politifact\":\n","  X_extra = politifact_df[['parsed_hour','parsed_month', 'publisher']].copy()\n","else:\n","  X_extra = gossipcop_df[['parsed_hour','parsed_month', 'publisher']].copy()"],"metadata":{"id":"8BQKHT5XlYSx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H0jXLXZu6y-o"},"outputs":[],"source":["X_extra['parsed_hour'] = X_extra['parsed_hour'].astype('str')\n","X_extra['parsed_month'] = X_extra['parsed_month'].astype('str')\n","X_extra['publisher'] = X_extra['publisher'].astype('str')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yr5NenKtWBg5"},"outputs":[],"source":["enc = OneHotEncoder(handle_unknown = 'ignore')\n","enc.fit(X_extra)\n","X_extra_enc = enc.transform(X_extra).toarray()"]},{"cell_type":"markdown","source":["# Experiment 1"],"metadata":{"id":"8gGkRjVGY1AS"}},{"cell_type":"markdown","source":["### Tokenizing"],"metadata":{"id":"T45jOiGUY1AT"}},{"cell_type":"code","source":["def tokenize(df, index_padded=None):\n","    # Get tokenizer\n","    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","    # tokenize text\n","    print(\"Tokenizing\")\n","    if type(index_padded) == 'NoneType':\n","        tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], tqdm(df['text'])))\n","        # Get token index\n","        indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, tokenized_df))\n","        # Pad tokens\n","        totalpadlength = 512\n","        index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in indexed_tokens])\n","        \n","    target_variable = df['target'].values\n","    article_flag = df[['is_pf']]\n","\n","    # Mask\n","    mask_variable = [[float(i>0) for i in ii] for ii in index_padded]\n","\n","    return index_padded, mask_variable, target_variable, article_flag\n","\n","def format_tensors(text_data, mask, labels, batch_size, flag):\n","    X = torch.from_numpy(text_data)\n","    X = X.long()\n","    mask = torch.tensor(mask)\n","    y = torch.from_numpy(labels)\n","    y = y.long()\n","    numerical_data = torch.from_numpy(flag)\n","    numerical_data = numerical_data.long()\n","\n","    tensordata = data_utils.TensorDataset(X, mask, numerical_data, y)\n","    loader = data_utils.DataLoader(tensordata, batch_size=batch_size, shuffle=False)\n","    return loader\n","\n","def train_validation_test(index_padded, mask_variable, target_variable, article_flag, BATCH_SIZE = 8):\n","    # Train test split for train set\n","    X_train, X_rest, y_train, y_rest = train_test_split(index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks, rest_masks, _, _ = train_test_split(mask_variable, index_padded, test_size=0.3, random_state=42)\n","    X_flag_train, X_flag_rest, _, _ = train_test_split(article_flag, index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state=42)\n","    val_masks, test_masks, _, _ = train_test_split(rest_masks, X_rest, test_size=0.5, random_state=42)\n","    X_flag_val, X_flag_test, _, _ = train_test_split(X_flag_rest, X_rest, test_size=0.5, random_state=42)\n","\n","    X_flag_train  = X_flag_train.is_pf.to_numpy()\n","    X_flag_val  = X_flag_val.is_pf.to_numpy()\n","    X_flag_test  = X_flag_test.is_pf.to_numpy()\n","\n","    trainloader = format_tensors(X_train, train_masks, y_train, BATCH_SIZE, X_flag_train.reshape(-1))\n","    validationloader = format_tensors(X_val, val_masks, y_val, BATCH_SIZE, X_flag_val.reshape(-1))\n","    testloader = format_tensors(X_test, test_masks, y_test, BATCH_SIZE, X_flag_test.reshape(-1))\n","\n","    return trainloader, validationloader, testloader"],"metadata":{"id":"WY53yx2SY1AT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_path = \"gdrive/MyDrive/BT4222/Code/machine_learning/xp/combined/\"\n","index_padded, mask_variable, target_variable, article_flag = tokenize(concat_df, np.load(open(f'{base_path}/index_padded.npy', 'rb')))\n","trainloader, validationloader, testloader = train_validation_test(index_padded, mask_variable, target_variable, article_flag)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1649945387831,"user_tz":-480,"elapsed":23380,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["9ae9c0e35709428aa0c0ec494d1aee7d","9223a84cff27447d9a6f08e8c88c2c75","41bc6b713ae44e058745e953b75031a6","1073db19a3c64657a38d080d97b7b9b1","afbaec7ac27e4876a7cdfee0185be42e","84fa6d177d284603b8ad8ed01d22c97b","e3fdce06f795496c8821ef931bee478e","3c3f04415e594d25ae36c6fc3b504e0d","b0ef2631748942a1b16398903291a7fb","cb7534d14195476bae6bb3112d85f4be","b7bfd7188e0e431e8915d29b67f86bfc","eb16d06535b748079ca1b24eb49ab8ec","84296f9c0ca6458a8eecd9b6e31de92a","ac8bd49ad5724d47b130f32b2f110edf","b285ab978b254a5f86d8875b4c0d49c2","72a587584922459295875e54c731b60c","53df01d0b9cb421c8b6fbbf3e4c46e4b","60a327490e6e46808823e50870191fab","16211d7402b34fe9840ca04ec596d75c","2739c56925fc491ba9893a08fd800a57","205de3515ee94f9880993c8dcac28efc","b1fe2d8336cc4ecc830cac4285032cef","62af8cf8e61b497bbfe4b30c88ac6e83","85dce318d5ea4cba9839f1a876239819","1831e9e99a1b4e3cad54193728ddf0e6","b360a3312db441fcb769b5937e6234cd","f8cf1a49ff514910bb6ccb762c922bb9","41fcac82b36244eb957c63b489ac5ab7","c0817f8ea75d4db28f84a715fd22fe4b","2f0bb0abba39415facc2dd4640a19696","c2a2d21b1660437f9893998fd5e581ea","d0dc68046d7d449d90b74bfaba003591","0bb464662a214d2b98882541ee9b7a87"]},"outputId":"b426c039-e49f-4c76-a789-8e27a939de50","id":"poW1E8E9Y1AV"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ae9c0e35709428aa0c0ec494d1aee7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb16d06535b748079ca1b24eb49ab8ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62af8cf8e61b497bbfe4b30c88ac6e83"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tokenizing\n"]}]},{"cell_type":"markdown","source":["### Model creation and test"],"metadata":{"id":"LyFCXqCwY1AX"}},{"cell_type":"code","source":["class BertAndFlag(torch.nn.Module):\n","    \"\"\"\n","    This takes a transformer backbone and puts a slightly-modified classification head on top.\n","    \n","    \"\"\"\n","\n","    def __init__(self):\n","        # num_extra_dims corresponds to the number of extra dimensions of numerical/categorical data\n","\n","        super().__init__()\n","\n","        # self.config = AutoConfig.from_pretrained(model_name)\n","        self.transformer = AutoModel.from_pretrained('distilbert-base-uncased') #Article transformer\n","        \n","        num_hidden_size = self.transformer.config.hidden_size # May be different depending on which model you use. Common sizes are 768 and 1024. Look in the config.json file \n","        # self.linear1 = torch.nn.Linear(num_hidden_size+num_extra_dims, 100)\n","        self.classifier = torch.nn.Linear(num_hidden_size+1, 2)\n","        # self.dropout = torch.nn.Dropout(0.25)\n","\n","    def forward(self, input_ids, extra_data, attention_mask=None, labels=None):\n","        \"\"\"\n","        extra_data should be of shape [batch_size, dim] \n","        where dim is the number of additional numerical/categorical dimensions\n","        \"\"\"\n","\n","        hidden_states = self.transformer(input_ids=input_ids, attention_mask=attention_mask) # [batch size, sequence length, hidden size]\n","\n","        cls_embeds = hidden_states.last_hidden_state[:, 0, :] # [batch size, hidden size]\n","\n","        concat = torch.cat((cls_embeds, extra_data.unsqueeze(dim=-1)), dim=-1) # [batch size, hidden size+num extra dims]\n","        output = self.classifier(concat)\n","        #x = self.dropout(x) \n","        #output = self.classifier(x) # [batch size, num labels]\n","\n","        return output"],"metadata":{"id":"J5GH4g4KZ0UK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def weighted_loss(loss_function, outputs, labels, is_pf, weights):\n","    '''\n","    loss_function outputs a 1D Tensor of Shape [1,]\n","    outputs: model outputs of shape [batch_size, 2 ]\n","    is_df : 1D tensor of shape [batch_size]\n","    weights: 1d tensor of shape [2] where first value corresponds to weight\n","    for pf and second for gc\n","    '''\n","    loss = loss_function(outputs,labels)\n","    #print(loss)\n","\n","    weight_vec = is_pf*weights[0] + (1-is_pf)*weights[1]\n","    #print(weight_vec)\n","    weighted_loss = weight_vec.mean()*loss\n","    #print(weighted_loss)\n","    return weighted_loss"],"metadata":{"id":"7_U4VoR3Z1Uv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loss weight\n","weight = [0,0]\n","weight[0] = concat_df.shape[0]/(2*politifact_df.shape[0])\n","weight[1] = concat_df.shape[0]/(2*gossipcop_df.shape[0])\n","weight = torch.tensor(weight).to(device)\n","\n","model = BertAndFlag()\n","checkpoint = torch.load(f\"gdrive/MyDrive/BT4222/Code/machine_learning/xp/Expt1/model_epoch3.pt\")\n","model.load_state_dict(checkpoint['model_state_dict'])\n","loss_function = nn.CrossEntropyLoss()\n","model.to(device)\n","with torch.set_grad_enabled(False):\n","    model.eval()\n","    epoch_loss = 0.0\n","    preds, truth, pred_proba, flag = [],[],[],[]\n","    iteration = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(tqdm(trainloader)):\n","            iteration += 1\n","            token_ids, masks, numerical, labels = tuple(t.to(device) for t in batch)\n","            outputs = model(input_ids=token_ids, extra_data=numerical, attention_mask=masks, labels=labels)\n","            loss = weighted_loss(loss_function, outputs, labels, numerical, weight)\n","            epoch_loss += float(loss.item())\n","\n","            # Metrics for batch\n","            epoch_loss += (float(loss.item()))\n","            prediction_proba = torch.sigmoid(outputs[:,1]).cpu().data.numpy()\n","            prediction = (prediction_proba > 0.5).astype(int)\n","            baseline = labels.long().cpu().data.numpy().astype(int)\n","            article_flag = numerical.long().cpu().data.numpy().astype(int)\n","            preds.extend(prediction)\n","            pred_proba.extend(prediction_proba)\n","            truth.extend(baseline)\n","            flag.extend(article_flag)\n","\n","            del token_ids, masks, numerical, labels #memory\n","            torch.cuda.empty_cache() #memory\n","            gc.collect() #memory\n","\n","    metrics = {}\n","    avg_accuracy, avg_roc_auc, avg_f1, avg_loss = accuracy_score(truth, preds), roc_auc_score(truth, pred_proba), f1_score(truth, preds), epoch_loss/float(iteration)\n","    print(f'Test Accuracy: 'f'{avg_accuracy:.2f}%')\n","    print(f'Test ROC AUC: 'f'{avg_roc_auc:.2f}%')\n","    print(f'Test F1: 'f'{avg_f1:.2f}%')\n","    print(f'Test loss: 'f'{avg_loss}%\\n')\n","    metrics['Test'] = {\n","        'accuracy':avg_accuracy,\n","        'roc_auc':avg_roc_auc,\n","        'f1':avg_f1,\n","        'loss':avg_loss\n","    }\n","    epoch_results = list(zip(preds, truth, pred_proba, flag))\n","\n","    # Politifact Validation\n","    politifact_results = list(filter(lambda x: x[3]==1, epoch_results))\n","    politifact_preds = list(map(lambda x: x[0], politifact_results))\n","    politifact_truth = list(map(lambda x: x[1], politifact_results))\n","    politifact_pred_proba = list(map(lambda x: x[2], politifact_results))\n","    avg_accuracy, avg_roc_auc, avg_f1 = accuracy_score(politifact_truth, politifact_preds), roc_auc_score(politifact_truth, politifact_pred_proba), f1_score(politifact_truth, politifact_preds)\n","    print(f'Politifact Test Accuracy: 'f'{avg_accuracy:.2f}%')\n","    print(f'Politifact Test ROC AUC: 'f'{avg_roc_auc:.2f}%')\n","    print(f'Politifact Test F1: 'f'{avg_f1:.2f}%')\n","    metrics['politifact_test'] = {\n","        'accuracy':avg_accuracy,\n","        'roc_auc':avg_roc_auc,\n","        'f1':avg_f1,\n","    }\n","    # Gossipcop Validation\n","    gossipcop_results = list(filter(lambda x: x[3]==0, epoch_results))\n","    gossipcop_preds = list(map(lambda x: x[0], gossipcop_results))\n","    gossipcop_truth = list(map(lambda x: x[1], gossipcop_results))\n","    gossipcop_pred_proba = list(map(lambda x: x[2], gossipcop_results))\n","    avg_accuracy, avg_roc_auc, avg_f1 = accuracy_score(gossipcop_truth, gossipcop_preds), roc_auc_score(gossipcop_truth, gossipcop_pred_proba), f1_score(gossipcop_truth, gossipcop_preds)\n","    print(f'Gossipcop Test Accuracy: 'f'{avg_accuracy:.2f}%')\n","    print(f'Gossipcop Test ROC AUC: 'f'{avg_roc_auc:.2f}%')\n","    print(f'Gossipcop Test F1: 'f'{avg_f1:.2f}%')\n","    metrics['gossipcop_test'] = {\n","        'accuracy':avg_accuracy,\n","        'roc_auc':avg_roc_auc,\n","        'f1':avg_f1,\n","    }\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341,"referenced_widgets":["29a78ccd9dd14895a587c42ff3aac786","ca270cfda0ad4cddbe92afd65e3745c5","c0ef30920a514e02b600edb4c8d9b3b2","f9759b3a1fd1456b878cec3ff11dbccf","566da2c42fe342b1945615f846cef3ab","fef3189dedce407db4b808bd42353c38","69acaac971f54c1ea0b09462433b7f88","84a156b118314c888e4fbc3043d54066","2d0ab482a11c40bd8788c633b462ec00","8fff605336794c63a862db718fa71866","d4e4eafc3a1f4ab08f1962ffe23e72b2"]},"executionInfo":{"status":"ok","timestamp":1649945960991,"user_tz":-480,"elapsed":269712,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"outputId":"e9ea2333-f4b4-466b-8598-952c866f1461","id":"FTSH99ZYY1AX"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29a78ccd9dd14895a587c42ff3aac786"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 394/394 [03:38<00:00,  1.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.84%\n","Test ROC AUC: 0.86%\n","Test F1: 0.89%\n","Test loss: 0.7754806158496871%\n","\n","Politifact Test Accuracy: 0.79%\n","Politifact Test ROC AUC: 0.85%\n","Politifact Test F1: 0.83%\n","Gossipcop Test Accuracy: 0.84%\n","Gossipcop Test ROC AUC: 0.85%\n","Gossipcop Test F1: 0.89%\n"]}]},{"cell_type":"markdown","source":["# Experiment 2"],"metadata":{"id":"uEb7JKKaXszU"}},{"cell_type":"markdown","source":["### Tokenizing"],"metadata":{"id":"CCKT0oL4DhVe"}},{"cell_type":"code","source":["def tokenize(df):\n","    # Get tokenizer\n","    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","    # tokenize text\n","    print(\"Tokenizing\")\n","    tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], tqdm(df['text'])))\n","    # Get token index\n","    indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, tokenized_df))\n","    # Pad tokens\n","    totalpadlength = 512\n","    index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in indexed_tokens])\n","    target_variable = df['target'].values\n","\n","    # Mask\n","    mask_variable = [[float(i>0) for i in ii] for ii in index_padded]\n","\n","    return index_padded, mask_variable, target_variable\n","\n","def format_tensors(text_data, mask, labels, batch_size):\n","    X = torch.from_numpy(text_data)\n","    X = X.long()\n","    mask = torch.tensor(mask)\n","    y = torch.from_numpy(labels)\n","    y = y.long()\n","    tensordata = data_utils.TensorDataset(X, mask, y)\n","    loader = data_utils.DataLoader(tensordata, batch_size=batch_size, shuffle=False)\n","    return loader\n","\n","def train_validation_test(index_padded, mask_variable, target_variable, BATCH_SIZE = 8):\n","    # Train test split for train set\n","    X_train, X_rest, y_train, y_rest = train_test_split(index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks, rest_masks, _, _ = train_test_split(mask_variable, index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state=42)\n","    val_masks, test_masks, _, _ = train_test_split(rest_masks, X_rest, test_size=0.5, random_state=42)\n","\n","    trainloader = format_tensors(X_train, train_masks, y_train, BATCH_SIZE)\n","    validationloader = format_tensors(X_val, val_masks, y_val, BATCH_SIZE)\n","    testloader = format_tensors(X_test, test_masks, y_test, BATCH_SIZE)\n","\n","    return trainloader, validationloader, testloader"],"metadata":{"id":"Grq1BMmYtK69"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Choose gossipcop or politifact\n","index_padded, mask_variable, target_variable = tokenize(politifact_df) if article == \"politifact\" else tokenize(gossipcop_df)\n","trainloader, validationloader, testloader = train_validation_test(index_padded, mask_variable, target_variable)"],"metadata":{"id":"WQBr8vpMwzlQ","executionInfo":{"status":"ok","timestamp":1649951091006,"user_tz":-480,"elapsed":361408,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3cfbacbf-e017-42d2-cf52-7f12f46402af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20049/20049 [05:41<00:00, 58.67it/s]\n"]}]},{"cell_type":"markdown","source":["### Model creation and test"],"metadata":{"id":"WZZ5aiGWYPZf"}},{"cell_type":"code","source":["model = AutoModelForSequenceClassification.from_pretrained(f\"gdrive/MyDrive/BT4222/Code/machine_learning/xp/{article}/Expt2/model_epoch2\")\n","model.to(device)\n","with torch.set_grad_enabled(False):\n","    model.eval()\n","    epoch_loss = 0.0\n","    preds, truth, pred_proba = [],[],[]\n","    iteration = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(tqdm(testloader)):\n","            iteration += 1\n","            token_ids, masks, labels = tuple(t.to(device) for t in batch)\n","            outputs = model(input_ids=token_ids, attention_mask=masks, labels=labels)\n","            loss = outputs['loss']\n","            yhat = outputs['logits']\n","\n","            # Metrics for batch\n","            epoch_loss += float(loss.item())\n","            prediction_proba = torch.sigmoid(yhat[:,1]).cpu().data.numpy()\n","            prediction = (prediction_proba > 0.5).astype(int)\n","            baseline = labels.long().cpu().data.numpy().astype(int)\n","            preds.extend(prediction)\n","            pred_proba.extend(prediction_proba)\n","            truth.extend(baseline)\n","\n","            del token_ids, masks, labels #memory\n","            torch.cuda.empty_cache() #memory\n","            gc.collect() #memory\n","\n","    avg_accuracy, avg_roc_auc, avg_f1, avg_loss = accuracy_score(truth, preds), roc_auc_score(truth, pred_proba), f1_score(truth, preds), epoch_loss/float(iteration)\n","    print(f'\\nTest Accuracy: 'f'{avg_accuracy:.2f}%')\n","    print(f'Test ROC AUC: 'f'{avg_roc_auc:.2f}%')\n","    print(f'Test F1: 'f'{avg_f1:.2f}%')\n","    print(f'Test loss: 'f'{avg_loss}%\\n')\n","    test_metrics = {\n","        'accuracy':avg_accuracy,\n","        'roc_auc':avg_roc_auc,\n","        'f1':avg_f1,\n","        'loss':avg_loss\n","    }"],"metadata":{"id":"GWgT2iUzxUa_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649951631490,"user_tz":-480,"elapsed":227107,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"outputId":"7bd2dc2f-7021-427f-c700-f7e3bf71f8b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 376/376 [03:38<00:00,  1.72it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.87%\n","Test ROC AUC: 0.90%\n","Test F1: 0.92%\n","Test loss: 0.3166738252522067%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# Experiment 3"],"metadata":{"id":"Tk1awUT-eXIC"}},{"cell_type":"markdown","source":["### Tokenizing"],"metadata":{"id":"cQY_HjBMeXID"}},{"cell_type":"code","source":["def tokenize(df):\n","    # Get tokenizer\n","    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","    # tokenize text\n","    print(\"Title Tokenizing\")\n","    title_tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:98] + ['[SEP]'], tqdm(df['title'])))\n","    # Get token index\n","    title_indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, title_tokenized_df))\n","    \n","    # Pad tokens\n","    totalpadlength = 100\n","    title_index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in title_indexed_tokens])\n","\n","    # Mask\n","    title_mask_variable = [[float(i>0) for i in ii] for ii in title_index_padded]\n","\n","\n","    print(\"Article Tokenizing\")\n","    article_tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], tqdm(df['text'])))    \n","    article_indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, article_tokenized_df))\n","  \n","    # Pad tokens\n","    totalpadlength = 512\n","    article_index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in article_indexed_tokens])\n","\n","    # Mask\n","    article_mask_variable = [[float(i>0) for i in ii] for ii in article_index_padded]\n","\n","    # Target Variable\n","    target_variable = df['target'].values\n","\n","    return title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, target_variable\n","\n","def format_tensors(article_data, article_mask, title_data, title_mask, labels, batch_size):\n","    \n","    X_article = torch.from_numpy(article_data)\n","    X_article = X_article.long()\n","    article_mask = torch.tensor(article_mask)\n","\n","    X_title = torch.from_numpy(title_data)\n","    X_title = X_title.long()\n","    title_mask = torch.tensor(title_mask)\n","\n","    y = torch.from_numpy(labels)\n","    y = y.long()\n","\n","    tensordata = data_utils.TensorDataset(X_article, article_mask, X_title, title_mask,  y)\n","    loader = data_utils.DataLoader(tensordata, batch_size=batch_size, shuffle=False)\n","    \n","    return loader\n","\n","def train_validation_test(title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, target_variable, BATCH_SIZE = 8):\n","    # Train test split for train set\n","    X_train_title, X_rest_title, y_train, y_rest = train_test_split(title_index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks_title, rest_masks_title, _, _ = train_test_split(title_mask_variable, title_index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_title, X_test_title, y_val, y_test = train_test_split(X_rest_title, y_rest, test_size=0.5, random_state=42)\n","    val_masks_title, test_masks_title, _, _ = train_test_split(rest_masks_title, X_rest_title, test_size=0.5, random_state=42)\n","\n","    # Train test split for train set\n","    X_train_article, X_rest_article, y_train, y_rest = train_test_split(article_index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks_article, rest_masks_article, _, _ = train_test_split(article_mask_variable, article_index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_article, X_test_article, y_val, y_test = train_test_split(X_rest_article, y_rest, test_size=0.5, random_state=42)\n","    val_masks_article, test_masks_article, _, _ = train_test_split(rest_masks_article, X_rest_article, test_size=0.5, random_state=42)\n","\n","    trainloader = format_tensors(X_train_article, train_masks_article, X_train_title, train_masks_title, y_train, BATCH_SIZE)\n","    validationloader = format_tensors(X_val_article, val_masks_article, X_val_title, val_masks_title, y_val, BATCH_SIZE)\n","    testloader = format_tensors(X_test_article, test_masks_article, X_test_title, test_masks_title, y_test, BATCH_SIZE)\n","\n","    return trainloader, validationloader, testloader"],"metadata":{"id":"26cEN9G0eXID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Choose gossipcop or politifact\n","title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, target_variable = tokenize(politifact_df) if article == \"politifact\" else tokenize(gossipcop_df)\n","trainloader, validationloader, testloader = train_validation_test(title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, target_variable)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1649959059991,"user_tz":-480,"elapsed":379751,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"58b03fae-3faa-4b5d-9f07-d08827c4166e","id":"ULaKWfeTeXIE"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Title Tokenizing\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20049/20049 [00:08<00:00, 2330.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Article Tokenizing\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20049/20049 [05:48<00:00, 57.58it/s]\n"]}]},{"cell_type":"markdown","source":["### Model creation and test"],"metadata":{"id":"O5vQK8U-eXIF"}},{"cell_type":"code","source":["model = torch.load(f\"gdrive/MyDrive/BT4222/Code/machine_learning/neil/{article}/Expt3/model_epoch6\")\n","loss_function = nn.CrossEntropyLoss()\n","model.to(device)\n","with torch.set_grad_enabled(False):\n","    model.eval()\n","    epoch_loss = 0.0\n","    preds, truth, pred_proba = [],[],[]\n","    iteration = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(tqdm(testloader)):\n","            iteration += 1\n","            article_token_ids, article_masks, title_token_ids, title_masks, labels = tuple(t.to(device) for t in batch)\n","            outputs = model(article_token_ids, article_masks, title_token_ids, title_masks, labels)\n","            loss = loss_function(outputs, labels)\n","            yhat = outputs\n","\n","            # Metrics for batch\n","            epoch_loss += float(loss.item())\n","            prediction_proba = torch.sigmoid(yhat[:,1]).cpu().data.numpy()\n","            prediction = (prediction_proba > 0.5).astype(int)\n","            baseline = labels.long().cpu().data.numpy().astype(int)\n","            preds.extend(prediction)\n","            pred_proba.extend(prediction_proba)\n","            truth.extend(baseline)\n","\n","            del article_token_ids, article_masks, title_token_ids, title_masks, labels #memory\n","            torch.cuda.empty_cache() #memory\n","            gc.collect() #memory\n","\n","    avg_accuracy, avg_roc_auc, avg_f1, avg_loss = accuracy_score(truth, preds), roc_auc_score(truth, pred_proba), f1_score(truth, preds), epoch_loss/float(iteration)\n","    print(f'\\nTest Accuracy: 'f'{avg_accuracy:.2f}%')\n","    print(f'Test ROC AUC: 'f'{avg_roc_auc:.2f}%')\n","    print(f'Test F1: 'f'{avg_f1:.2f}%')\n","    print(f'Test loss: 'f'{avg_loss}%\\n')\n","    test_metrics = {\n","        'accuracy':avg_accuracy,\n","        'roc_auc':avg_roc_auc,\n","        'f1':avg_f1,\n","        'loss':avg_loss\n","    }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dbdafbe3-47af-424a-880b-90eefb823fc9","id":"e8zdIlbweXIG","executionInfo":{"status":"ok","timestamp":1649959303226,"user_tz":-480,"elapsed":243240,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 376/376 [03:52<00:00,  1.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.89%\n","Test ROC AUC: 0.92%\n","Test F1: 0.93%\n","Test loss: 0.33495429144154226%\n","\n"]}]},{"cell_type":"markdown","source":["# Experiment 4"],"metadata":{"id":"DG-vpx1SmnO_"}},{"cell_type":"markdown","source":["### Tokenizing"],"metadata":{"id":"KpJJd-4JmnPD"}},{"cell_type":"code","source":["def tokenize(df):\n","    # Get tokenizer\n","    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","    # tokenize text\n","    print(\"Title Tokenizing\")\n","    title_tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:98] + ['[SEP]'], tqdm(df['title'])))\n","    # Get token index\n","    title_indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, title_tokenized_df))\n","    \n","    # Pad tokens\n","    totalpadlength = 100\n","    title_index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in title_indexed_tokens])\n","\n","    # Mask\n","    title_mask_variable = [[float(i>0) for i in ii] for ii in title_index_padded]\n","\n","\n","    print(\"Article Tokenizing\")\n","    article_tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], tqdm(df['text'])))    \n","    article_indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, article_tokenized_df))\n","  \n","    # Pad tokens\n","    totalpadlength = 512\n","    article_index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in article_indexed_tokens])\n","\n","    # Mask\n","    article_mask_variable = [[float(i>0) for i in ii] for ii in article_index_padded]\n","\n","    # Target Variable\n","    target_variable = df['target'].values\n","\n","    return title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, target_variable\n","\n","def format_tensors(article_data, article_mask, title_data, title_mask, extra_features, labels, batch_size):\n","    \n","    X_article = torch.from_numpy(article_data)\n","    X_article = X_article.long()\n","    article_mask = torch.tensor(article_mask)\n","\n","    X_title = torch.from_numpy(title_data)\n","    X_title = X_title.long()\n","    title_mask = torch.tensor(title_mask)\n","\n","    extra_features = torch.from_numpy(extra_features)\n","    extra_features = extra_features.long()\n","\n","    y = torch.from_numpy(labels)\n","    y = y.long()\n","\n","    tensordata = data_utils.TensorDataset(X_article, article_mask, X_title, title_mask, extra_features,  y)\n","    loader = data_utils.DataLoader(tensordata, batch_size=batch_size, shuffle=False)\n","    \n","    return loader\n","\n","def train_validation_test(title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, X_extra, target_variable, BATCH_SIZE = 8):\n","    # Train test split for train set\n","    X_train_title, X_rest_title, y_train, y_rest = train_test_split(title_index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks_title, rest_masks_title, _, _ = train_test_split(title_mask_variable, title_index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_title, X_test_title, y_val, y_test = train_test_split(X_rest_title, y_rest, test_size=0.5, random_state=42)\n","    val_masks_title, test_masks_title, _, _ = train_test_split(rest_masks_title, X_rest_title, test_size=0.5, random_state=42)\n","\n","    # Train test split for train set\n","    X_train_article, X_rest_article, _, _ = train_test_split(article_index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks_article, rest_masks_article, _, _ = train_test_split(article_mask_variable, article_index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_article, X_test_article, _, _ = train_test_split(X_rest_article, y_rest, test_size=0.5, random_state=42)\n","    val_masks_article, test_masks_article, _, _ = train_test_split(rest_masks_article, X_rest_article, test_size=0.5, random_state=42)\n","\n","    # Train test split for train set\n","    X_train_extra, X_rest_extra, _, _ = train_test_split(X_extra, target_variable, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_extra, X_test_extra, _, _ = train_test_split(X_rest_extra, y_rest, test_size=0.5, random_state=42)\n","\n","    trainloader = format_tensors(X_train_article, train_masks_article, X_train_title, train_masks_title, X_train_extra, y_train, BATCH_SIZE)\n","    validationloader = format_tensors(X_val_article, val_masks_article, X_val_title, val_masks_title, X_val_extra, y_val, BATCH_SIZE)\n","    testloader = format_tensors(X_test_article, test_masks_article, X_test_title, test_masks_title, X_test_extra, y_test, BATCH_SIZE)\n","\n","    return trainloader, validationloader, testloader"],"metadata":{"id":"-WiSe58ZmnPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, target_variable = tokenize(politifact_df) if article == \"politifact\" else tokenize(gossipcop_df)\n","trainloader, validationloader, testloader = train_validation_test(title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, X_extra_enc, target_variable)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["b24c47da72a74a2591a1f6450ee0561f","c9be991286be4d10a65ff603f92c7efe","47df2fc7ea01440b9b5ec73dd0a05772","42a5f0dc53804857a8a8a45b02c5de0c","9ea997c5d77248f1af38aa676ea4b924","ee120579b2b744ed8e6878a946cfb7fe","838c9ef4fbb840e396022f1dc70e271f","b9d570bd7ee34727b1bbe7b72b3c055f","5a8d160143694e8993f7042fbe1f9ff7","58cbc6f90bef4a368c6ac5e8dd60fad1","ffadf5eb968c4d3a88480e166805787f","bd38a46b741b40778fc6b16593fcf7cd","50bc6fbd39144daaba1a2b2f78f758dc","1529288b8ade4a9aa384c7f11231e586","d252bece78114029a0cbef50a0253481","569aed5ab2614e6b88ae196f464ae44d","9cfd898281464f4a926e4a397b7488a3","be5a256747184fc9ac934adb7d249621","4251af3e3e54446cbbf2e296e4794773","6e3b2c75a08743f98c7d5f7249e89ded","6f35036c131b454c96c129af61fbd2e2","312e0a70b180469f8264d698111c6388","6fa3d6b17fab4de7bec58c255833f005","aa16863c7ac649c387cc953d8dd9ee5a","922c9edf56fb4706ad857295e81bc776","3c8eb825b33b4ed0a3d7e39652bb125e","faeafbb5fc8e4ecf9b1510e6041032cd","6812f3638d124c2e9d1d86b0cf9dd775","8899b635ee5f4cf295e7765a995b4f09","39f5c769d5c8482db88f0287dce8496d","a77ca2d78c2c43ba9e1bf9df810c77f4","d0ea101a47784052a716cd55d2dfca83","008362e67af745ebbf550b044dc2ad33"]},"executionInfo":{"status":"ok","timestamp":1649958017909,"user_tz":-480,"elapsed":390320,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"outputId":"243f2a05-3e8f-47bc-c301-1966e6b07370","id":"1A2_NcdWmnPE"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b24c47da72a74a2591a1f6450ee0561f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd38a46b741b40778fc6b16593fcf7cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fa3d6b17fab4de7bec58c255833f005"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Title Tokenizing\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20049/20049 [00:09<00:00, 2212.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Article Tokenizing\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20049/20049 [05:55<00:00, 56.35it/s]\n"]}]},{"cell_type":"markdown","source":["### Model creation and test"],"metadata":{"id":"v9vkoPqwmnPE"}},{"cell_type":"code","source":["model = torch.load(f\"gdrive/MyDrive/BT4222/Code/machine_learning/neil/{article}/Expt4/model_epoch7\")\n","loss_function = nn.CrossEntropyLoss()\n","model.to(device)\n","with torch.set_grad_enabled(False):\n","    model.eval()\n","    epoch_loss = 0.0\n","    preds, truth, pred_proba = [],[],[]\n","    loss_function = nn.CrossEntropyLoss()\n","    iteration = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(tqdm(testloader)):\n","            iteration += 1\n","            article_token_ids, article_masks, title_token_ids, title_masks, extra_features, labels = tuple(t.to(device) for t in batch)\n","            outputs = model(article_token_ids, article_masks, title_token_ids, title_masks, extra_features, labels)\n","            \n","            loss = loss_function(outputs, labels)\n","            epoch_loss += float(loss.item())\n","            yhat = outputs\n","            prediction_proba = torch.sigmoid(yhat[:,1]).cpu().data.numpy()\n","            prediction = (prediction_proba > 0.5).astype(int)\n","            baseline = labels.long().cpu().data.numpy().astype(int)\n","            preds.extend(prediction)\n","            pred_proba.extend(prediction_proba)\n","            truth.extend(baseline)\n","\n","            del article_token_ids, article_masks, title_token_ids, title_masks, extra_features, labels #memory\n","            torch.cuda.empty_cache() #memory\n","            gc.collect() #memory\n","\n","    avg_accuracy, avg_roc_auc, avg_f1, avg_loss = accuracy_score(truth, preds), roc_auc_score(truth, pred_proba), f1_score(truth, preds), epoch_loss/float(iteration)\n","    print(f'\\nTest Accuracy: 'f'{avg_accuracy:.2f}%')\n","    print(f'Test ROC AUC: 'f'{avg_roc_auc:.2f}%')\n","    print(f'Test F1: 'f'{avg_f1:.2f}%')\n","    print(f'Test loss: 'f'{avg_loss}%\\n')\n","    test_metrics = {\n","        'accuracy':avg_accuracy,\n","        'roc_auc':avg_roc_auc,\n","        'f1':avg_f1,\n","        'loss':avg_loss\n","    }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9d0633e-3334-4cbc-a0ba-e6fb6601c30e","executionInfo":{"status":"ok","timestamp":1649958278352,"user_tz":-480,"elapsed":260451,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"id":"lA-QUo_DmnPF"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 376/376 [03:55<00:00,  1.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.89%\n","Test ROC AUC: 0.92%\n","Test F1: 0.93%\n","Test loss: 0.3363721717825219%\n","\n"]}]},{"cell_type":"markdown","source":["# Experiment 5"],"metadata":{"id":"o3Q4Kr2siDYA"}},{"cell_type":"markdown","metadata":{"id":"5Px8Oug-Y_sO"},"source":["### Summarizing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PngGR_bcZRhD"},"outputs":[],"source":["%%capture\n","!pip install sumy\n","import sumy\n","from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer\n","from sumy.summarizers.lex_rank import LexRankSummarizer\n","\n","from sumy.nlp.stemmers import Stemmer\n","from sumy.utils import get_stop_words\n","from gensim.summarization import summarize\n","from sumy.utils import get_stop_words\n","from sumy.nlp.tokenizers import Tokenizer as sumytoken\n","from sumy.nlp.stemmers import Stemmer\n","from sumy.summarizers.luhn import LuhnSummarizer\n","\n","# For TextRank\n","import nltk\n","nltk.download('punkt') # one time execution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdSOpO6LY9jF"},"outputs":[],"source":["def luhn_summarizer(text, LANGUAGE, SENTENCES_COUNT):\n","    parser = PlaintextParser.from_string(text, sumytoken(LANGUAGE))\n","    sentences = []\n","    for sentence in summarizer_luhn(parser.document, SENTENCES_COUNT):\n","        a = sentence\n","        sentences.append(str(a))\n","    return \" \".join(sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ubGl9SaZrgM"},"outputs":[],"source":["LANGUAGE = \"english\"\n","SENTENCES_COUNT = 15 # dk how to collaborate this\n","stemmer = Stemmer(LANGUAGE)\n","summarizer_luhn = LuhnSummarizer(stemmer)\n","summarizer_luhn.stop_words = get_stop_words(LANGUAGE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJ_dbn8QbORd"},"outputs":[],"source":["#gossipcop_df['text_summarised'] = gossipcop_df['text'].apply(lambda x: luhn_summarizer(x, LANGUAGE,SENTENCES_COUNT))\n","politifact_df['text_summarised'] = politifact_df['text'].apply(lambda x: luhn_summarizer(x, LANGUAGE,SENTENCES_COUNT))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndWCNOTLiP9m"},"outputs":[],"source":["politifact_df['text_summarised_len'] = politifact_df['text_summarised'].str.split().str.len()\n","\n","#gossipcop_df['text_summarised_len'] = gossipcop_df['text_summarised'].str.split().str.len()"]},{"cell_type":"markdown","source":["### Tokenizing"],"metadata":{"id":"KJImwF75iDYM"}},{"cell_type":"code","source":["def tokenize(df):\n","    # Get tokenizer\n","    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","    # tokenize text\n","    print(\"Title Tokenizing\")\n","    title_tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:98] + ['[SEP]'], tqdm(df['title'])))\n","    # Get token index\n","    title_indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, title_tokenized_df))\n","    \n","    # Pad tokens\n","    totalpadlength = 100\n","    title_index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in title_indexed_tokens])\n","\n","    # Mask\n","    title_mask_variable = [[float(i>0) for i in ii] for ii in title_index_padded]\n","\n","\n","    print(\"Article Tokenizing\")\n","    article_tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], tqdm(df['text_summarised'])))    \n","    article_indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, article_tokenized_df))\n","  \n","    # Pad tokens\n","    totalpadlength = 512\n","    article_index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in article_indexed_tokens])\n","\n","    # Mask\n","    article_mask_variable = [[float(i>0) for i in ii] for ii in article_index_padded]\n","\n","    # Target Variable\n","    target_variable = df['target'].values\n","\n","    return title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, target_variable\n","\n","def format_tensors(article_data, article_mask, title_data, title_mask, extra_features, labels, batch_size):\n","    \n","    X_article = torch.from_numpy(article_data)\n","    X_article = X_article.long()\n","    article_mask = torch.tensor(article_mask)\n","\n","    X_title = torch.from_numpy(title_data)\n","    X_title = X_title.long()\n","    title_mask = torch.tensor(title_mask)\n","\n","    extra_features = torch.from_numpy(extra_features)\n","    extra_features = extra_features.long()\n","\n","    y = torch.from_numpy(labels)\n","    y = y.long()\n","\n","    tensordata = data_utils.TensorDataset(X_article, article_mask, X_title, title_mask, extra_features,  y)\n","    loader = data_utils.DataLoader(tensordata, batch_size=batch_size, shuffle=False)\n","    \n","    return loader\n","\n","def train_validation_test(title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, X_extra, target_variable, BATCH_SIZE = 8):\n","    # Train test split for train set\n","    X_train_title, X_rest_title, y_train, y_rest = train_test_split(title_index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks_title, rest_masks_title, _, _ = train_test_split(title_mask_variable, title_index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_title, X_test_title, y_val, y_test = train_test_split(X_rest_title, y_rest, test_size=0.5, random_state=42)\n","    val_masks_title, test_masks_title, _, _ = train_test_split(rest_masks_title, X_rest_title, test_size=0.5, random_state=42)\n","\n","    # Train test split for train set\n","    X_train_article, X_rest_article, _, _ = train_test_split(article_index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks_article, rest_masks_article, _, _ = train_test_split(article_mask_variable, article_index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_article, X_test_article, _, _ = train_test_split(X_rest_article, y_rest, test_size=0.5, random_state=42)\n","    val_masks_article, test_masks_article, _, _ = train_test_split(rest_masks_article, X_rest_article, test_size=0.5, random_state=42)\n","\n","    # Train test split for train set\n","    X_train_extra, X_rest_extra, _, _ = train_test_split(X_extra, target_variable, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_extra, X_test_extra, _, _ = train_test_split(X_rest_extra, y_rest, test_size=0.5, random_state=42)\n","\n","    trainloader = format_tensors(X_train_article, train_masks_article, X_train_title, train_masks_title, X_train_extra, y_train, BATCH_SIZE)\n","    validationloader = format_tensors(X_val_article, val_masks_article, X_val_title, val_masks_title, X_val_extra, y_val, BATCH_SIZE)\n","    testloader = format_tensors(X_test_article, test_masks_article, X_test_title, test_masks_title, X_test_extra, y_test, BATCH_SIZE)\n","\n","    return trainloader, validationloader, testloader"],"metadata":{"id":"-R6mmI37iDYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, target_variable = tokenize(politifact_df) if article == \"politifact\" else tokenize(gossipcop_df)\n","trainloader, validationloader, testloader = train_validation_test(title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, X_extra_enc, target_variable)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMsOA3_0lk55","executionInfo":{"status":"ok","timestamp":1649948397646,"user_tz":-480,"elapsed":12180,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"outputId":"944cd5a2-3199-4680-893a-cc47884f745b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Title Tokenizing\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 954/954 [00:00<00:00, 2762.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Article Tokenizing\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 954/954 [00:07<00:00, 136.08it/s]\n"]}]},{"cell_type":"markdown","source":["### Model creation and test"],"metadata":{"id":"LT5y5i5viDYN"}},{"cell_type":"code","source":["model = torch.load(f\"gdrive/MyDrive/BT4222/Code/machine_learning/neil/{article}/Expt5/model_epoch3\")\n","loss_function = nn.CrossEntropyLoss()\n","model.to(device)\n","with torch.set_grad_enabled(False):\n","    model.eval()\n","    epoch_loss = 0.0\n","    preds, truth, pred_proba = [],[],[]\n","    iteration = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(tqdm(testloader)):\n","            iteration += 1\n","            article_token_ids, article_masks, title_token_ids, title_masks, extra_features, labels = tuple(t.to(device) for t in batch)\n","            outputs = model(article_token_ids, article_masks, title_token_ids, title_masks, extra_features, labels)\n","            \n","            loss = loss_function(outputs, labels)\n","            epoch_loss += float(loss.item())\n","            yhat = outputs\n","            prediction_proba = torch.sigmoid(yhat[:,1]).cpu().data.numpy()\n","            prediction = (prediction_proba > 0.5).astype(int)\n","            baseline = labels.long().cpu().data.numpy().astype(int)\n","            preds.extend(prediction)\n","            pred_proba.extend(prediction_proba)\n","            truth.extend(baseline)\n","\n","            del article_token_ids, article_masks, title_token_ids, title_masks, extra_features, labels #memory\n","            torch.cuda.empty_cache() #memory\n","            gc.collect() #memory\n","\n","    avg_accuracy, avg_roc_auc, avg_f1, avg_loss = accuracy_score(truth, preds), roc_auc_score(truth, pred_proba), f1_score(truth, preds), epoch_loss/float(iteration)\n","    print(f'\\nTest Accuracy: 'f'{avg_accuracy:.2f}%')\n","    print(f'Test ROC AUC: 'f'{avg_roc_auc:.2f}%')\n","    print(f'Test F1: 'f'{avg_f1:.2f}%')\n","    print(f'Test loss: 'f'{avg_loss}%\\n')\n","    test_metrics = {\n","        'accuracy':avg_accuracy,\n","        'roc_auc':avg_roc_auc,\n","        'f1':avg_f1,\n","        'loss':avg_loss\n","    }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"38087c64-ab00-49b3-c28e-e2c11b99f2ac","executionInfo":{"status":"ok","timestamp":1649948628074,"user_tz":-480,"elapsed":13858,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"id":"gvUq0yrLiDYO"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 18/18 [00:11<00:00,  1.50it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.89%\n","Test ROC AUC: 0.96%\n","Test F1: 0.91%\n","Test loss: 0.3030630453593201%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# Experiment 6"],"metadata":{"id":"v6iYWRpdn79w"}},{"cell_type":"markdown","metadata":{"id":"eb33L_DkoCnV"},"source":["### Tokenizing - TF-idf\n","\n","We don't use CV as it performs much poorly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHxAk8OYoCnV"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","def tokenize(df):\n","    # Get tokenizer\n","    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","    # tokenize text\n","    print(\"Title Tokenizing\")\n","    title_tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:98] + ['[SEP]'], tqdm(df['title'])))\n","    # Get token index\n","    title_indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, title_tokenized_df))\n","    \n","    # Pad tokens\n","    totalpadlength = 100\n","    title_index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in title_indexed_tokens])\n","\n","    # Mask\n","    title_mask_variable = [[float(i>0) for i in ii] for ii in title_index_padded]\n","\n","    # Target Variable\n","    target_variable = df['target'].values\n","\n","    # Article text\n","    article_text = df.text_clean.values\n","\n","    return title_index_padded, title_mask_variable, article_text, target_variable\n","\n","def format_tensors(article_text, title_data, title_mask, extra_features, labels, batch_size):\n","    \n","    X_article = torch.from_numpy(article_text)\n","    X_article = X_article.long()\n","\n","    X_title = torch.from_numpy(title_data)\n","    X_title = X_title.long()\n","    title_mask = torch.tensor(title_mask)\n","\n","    extra_features = torch.from_numpy(extra_features)\n","    extra_features = extra_features.long()\n","\n","    y = torch.from_numpy(labels)\n","    y = y.long()\n","\n","    tensordata = data_utils.TensorDataset(X_article, X_title, title_mask, extra_features,  y)\n","    loader = data_utils.DataLoader(tensordata, batch_size=batch_size, shuffle=False)\n","    \n","    return loader\n","\n","def train_validation_test(title_index_padded, title_mask_variable, article_text, X_extra, target_variable, BATCH_SIZE = 8):\n","    # TITLE #\n","    # Train test split for train set\n","    X_train_title, X_rest_title, y_train, y_rest = train_test_split(title_index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks_title, rest_masks_title, _, _ = train_test_split(title_mask_variable, title_index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_title, X_test_title, y_val, y_test = train_test_split(X_rest_title, y_rest, test_size=0.5, random_state=42)\n","    val_masks_title, test_masks_title, _, _ = train_test_split(rest_masks_title, X_rest_title, test_size=0.5, random_state=42)\n","\n","    # ARTICLE #\n","    # Train test split for train set\n","    X_train_article, X_rest_article, _, _ = train_test_split(article_text, target_variable, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_article, X_test_article, _, _ = train_test_split(X_rest_article, y_rest, test_size=0.5, random_state=42)\n","\n","    vect = TfidfVectorizer(max_features=20000)\n","    X_train_article_dtm = vect.fit_transform(X_train_article).toarray()\n","    X_test_article_dtm = vect.transform(X_test_article).toarray()\n","    X_val_article_dtm = vect.transform(X_val_article).toarray()\n","\n","    # Extra Features #\n","    # Train test split for train set\n","    X_train_extra, X_rest_extra, _, _ = train_test_split(X_extra, target_variable, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_extra, X_test_extra, _, _ = train_test_split(X_rest_extra, y_rest, test_size=0.5, random_state=42)\n","\n","    enc = OneHotEncoder(handle_unknown = 'ignore')\n","    enc.fit(X_train_extra)\n","    X_train_extra_enc = enc.transform(X_train_extra).toarray()\n","    X_test_extra_enc = enc.transform(X_test_extra).toarray()\n","    X_val_extra_enc = enc.transform(X_val_extra).toarray()\n","\n","\n","    trainloader = format_tensors(X_train_article_dtm, X_train_title, train_masks_title, X_train_extra_enc, y_train, BATCH_SIZE)\n","    validationloader = format_tensors(X_val_article_dtm, X_val_title, val_masks_title, X_val_extra_enc, y_val, BATCH_SIZE)\n","    testloader = format_tensors(X_test_article_dtm, X_test_title, test_masks_title, X_test_extra_enc, y_test, BATCH_SIZE)\n","\n","    return trainloader, validationloader, testloader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"32c31a9e-a973-44fa-d3e5-e2b61d2296fa","id":"TaBjrFNeoCnW","executionInfo":{"status":"ok","timestamp":1649952685885,"user_tz":-480,"elapsed":27942,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Title Tokenizing\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20049/20049 [00:11<00:00, 1746.04it/s]\n"]}],"source":["title_index_padded, title_mask_variable, article_text, target_variable = tokenize(politifact_df) if article == \"politifact\" else tokenize(gossipcop_df)\n","trainloader, validationloader, testloader = train_validation_test(title_index_padded, title_mask_variable, article_text, X_extra, target_variable)"]},{"cell_type":"markdown","source":["### Model creation and test"],"metadata":{"id":"O56lmWpVn793"}},{"cell_type":"code","source":["model = torch.load(f\"gdrive/MyDrive/BT4222/Code/machine_learning/neil/{article}/Expt6/model_epoch5\")\n","loss_function = nn.CrossEntropyLoss()\n","model.to(device)\n","with torch.set_grad_enabled(False):\n","    model.eval()\n","    epoch_loss = 0.0\n","    loss_function = nn.CrossEntropyLoss()\n","    preds, truth, pred_proba = [],[],[]\n","    iteration = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(tqdm(testloader)):\n","            iteration += 1\n","            article_input, title_input_ids, title_attention_mask, extra_features, labels = tuple(t.to(device) for t in batch)\n","            outputs = model(article_input, title_input_ids, title_attention_mask, extra_features)\n","            \n","            loss = loss_function(outputs, labels)\n","            epoch_loss += float(loss.item())\n","            yhat = outputs\n","            prediction_proba = torch.sigmoid(yhat[:,1]).cpu().data.numpy()\n","            prediction = (prediction_proba > 0.5).astype(int)\n","            baseline = labels.long().cpu().data.numpy().astype(int)\n","            preds.extend(prediction)\n","            pred_proba.extend(prediction_proba)\n","            truth.extend(baseline)\n","\n","            del article_input, title_input_ids, title_attention_mask, extra_features, labels #memory\n","            torch.cuda.empty_cache() #memory\n","            gc.collect() #memory\n","\n","    avg_accuracy, avg_roc_auc, avg_f1, avg_loss = accuracy_score(truth, preds), roc_auc_score(truth, pred_proba), f1_score(truth, preds), epoch_loss/float(iteration)\n","    print(f'\\nTest Accuracy: 'f'{avg_accuracy:.2f}%')\n","    print(f'Test ROC AUC: 'f'{avg_roc_auc:.2f}%')\n","    print(f'Test F1: 'f'{avg_f1:.2f}%')\n","    print(f'Test loss: 'f'{avg_loss}%\\n')\n","    test_metrics = {\n","        'accuracy':avg_accuracy,\n","        'roc_auc':avg_roc_auc,\n","        'f1':avg_f1,\n","        'loss':avg_loss\n","    }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"877303ea-3dbe-49cd-d8c1-86d327258b8f","executionInfo":{"status":"ok","timestamp":1649952795549,"user_tz":-480,"elapsed":109681,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"id":"TNxU3254n794"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 376/376 [01:48<00:00,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.84%\n","Test ROC AUC: 0.88%\n","Test F1: 0.90%\n","Test loss: 0.4561593482834956%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# Experiment 7"],"metadata":{"id":"nhVCC9vupVUO"}},{"cell_type":"markdown","metadata":{"id":"OOTixzmFp9X3"},"source":["### Loading Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTmbk79qp9X4"},"outputs":[],"source":["politifact_data = json.load(open(\"gdrive/MyDrive/BT4222/Data/politifact_combined.json\", \"r\"))\n","gossipcop_data = json.load(open(\"gdrive/MyDrive/BT4222/Data/gossipcop_combined.json\", \"r\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKyNLUOatsxT"},"outputs":[],"source":["politifact_df = pd.DataFrame(politifact_data)\n","gossipcop_df = pd.DataFrame(gossipcop_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gmi8OF_Rt84h"},"outputs":[],"source":["politifact_df['target'] = politifact_df['label'].apply(lambda x: 1 if x=='real' else 0)\n","gossipcop_df['target'] = gossipcop_df['label'].apply(lambda x: 1 if x=='real' else 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYIlotpvp9X5"},"outputs":[],"source":["politifact_df['parsed_month'] = politifact_df['publish_date'].apply(lambda x: dt.datetime.fromtimestamp(x).strftime(\"%m\") if not pd.isna(x) else '0')\n","gossipcop_df['parsed_month'] = gossipcop_df['publish_date'].apply(lambda x: dt.datetime.fromtimestamp(x).strftime(\"%m\") if not pd.isna(x) else '0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-yhuIZOp9X5"},"outputs":[],"source":["politifact_df['parsed_hour'] = politifact_df['publish_date'].apply(lambda x: dt.datetime.fromtimestamp(x).strftime(\"%H\") if not pd.isna(x) else '0')\n","gossipcop_df['parsed_hour'] = gossipcop_df['publish_date'].apply(lambda x: dt.datetime.fromtimestamp(x).strftime(\"%H\") if not pd.isna(x) else '0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdCoJiYIp9X5"},"outputs":[],"source":["politifact_df['publisher'] = politifact_df['publisher'].fillna('None')\n","gossipcop_df['publisher'] = gossipcop_df['publisher'].fillna('None')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuqZOs8hbJCr"},"outputs":[],"source":["if article == \"politifact\":\n","  X_extra = politifact_df[['parsed_hour','parsed_month', 'publisher']]\n","else:\n","  X_extra = gossipcop_df[['parsed_hour','parsed_month', 'publisher']]"]},{"cell_type":"code","source":["X_extra['parsed_hour'] = X_extra['parsed_hour'].astype('str')\n","X_extra['parsed_month'] = X_extra['parsed_month'].astype('str')\n","X_extra['publisher'] = X_extra['publisher'].astype('str')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZawoC-49mgf","executionInfo":{"status":"ok","timestamp":1649950334757,"user_tz":-480,"elapsed":4,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"outputId":"c5b29aeb-0cde-4a65-96db-72a4fe63bfb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}]},{"cell_type":"markdown","metadata":{"id":"h-8I0SUsp9X7"},"source":["### Tokenizing - TF-idf\n","\n","We don't use CV as it performs much poorly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-Lncasip9X7"},"outputs":[],"source":["def tokenize(df):\n","    # Get tokenizer\n","    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","    # tokenize text\n","    print(\"Title Tokenizing\")\n","    title_tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:98] + ['[SEP]'], tqdm(df['title'])))\n","    # Get token index\n","    title_indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, title_tokenized_df))\n","    \n","    # Pad tokens\n","    totalpadlength = 100\n","    title_index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in title_indexed_tokens])\n","\n","    # Mask\n","    title_mask_variable = [[float(i>0) for i in ii] for ii in title_index_padded]\n","\n","\n","    print(\"Article Tokenizing\")\n","    article_tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], tqdm(df['text'])))    \n","    article_indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, article_tokenized_df))\n","  \n","    # Pad tokens\n","    totalpadlength = 512\n","    article_index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in article_indexed_tokens])\n","\n","    # Mask\n","    article_mask_variable = [[float(i>0) for i in ii] for ii in article_index_padded]\n","  \n","    # Article text\n","    tweets_text = df.tweets_text.values\n","\n","    # Target Variable\n","    target_variable = df['target'].values\n","\n","    return title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, tweets_text, target_variable\n","\n","def format_tensors(article_data, article_mask, title_data, title_mask, extra_features, tweets_text, labels, batch_size):\n","    \n","    X_article = torch.from_numpy(article_data)\n","    X_article = X_article.long()\n","    article_mask = torch.tensor(article_mask)\n","\n","    X_title = torch.from_numpy(title_data)\n","    X_title = X_title.long()\n","    title_mask = torch.tensor(title_mask)\n","\n","    extra_features = torch.from_numpy(extra_features)\n","    extra_features = extra_features.long()\n","\n","    tweets_text = torch.from_numpy(tweets_text)\n","    tweets_text = tweets_text.long()    \n","\n","    y = torch.from_numpy(labels)\n","    y = y.long()\n","\n","    tensordata = data_utils.TensorDataset(X_article, article_mask, X_title, title_mask, extra_features,tweets_text,  y)\n","    loader = data_utils.DataLoader(tensordata, batch_size=batch_size, shuffle=False)\n","    \n","    return loader\n","\n","def train_validation_test(title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, tweets_text, target_variable, BATCH_SIZE = 8):\n","\n","    # Train test split for train set\n","    X_train_title, X_rest_title, y_train, y_rest = train_test_split(title_index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks_title, rest_masks_title, _, _ = train_test_split(title_mask_variable, title_index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_title, X_test_title, y_val, y_test = train_test_split(X_rest_title, y_rest, test_size=0.5, random_state=42)\n","    val_masks_title, test_masks_title, _, _ = train_test_split(rest_masks_title, X_rest_title, test_size=0.5, random_state=42)\n","\n","    # Train test split for train set\n","    X_train_article, X_rest_article, y_train, y_rest = train_test_split(article_index_padded, target_variable, test_size=0.3, random_state=42)\n","    train_masks_article, rest_masks_article, _, _ = train_test_split(article_mask_variable, article_index_padded, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_article, X_test_article, y_val, y_test = train_test_split(X_rest_article, y_rest, test_size=0.5, random_state=42)\n","    val_masks_article, test_masks_article, _, _ = train_test_split(rest_masks_article, X_rest_article, test_size=0.5, random_state=42)\n","\n","\n","    # Tweets #\n","    # Train test split for train set\n","    X_train_tweet, X_rest_tweet, _, _ = train_test_split(tweets_text, target_variable, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_tweet, X_test_tweet, _, _ = train_test_split(X_rest_tweet, y_rest, test_size=0.5, random_state=42)\n","\n","    vect = TfidfVectorizer(max_features=10000)\n","    X_train_tweet_dtm = vect.fit_transform(X_train_tweet).toarray()\n","    X_test_tweet_dtm = vect.transform(X_test_tweet).toarray()\n","    X_val_tweet_dtm = vect.transform(X_val_tweet).toarray()\n","\n","    # Extra Features #\n","    # Train test split for train set\n","    X_train_extra, X_rest_extra, _, _ = train_test_split(X_extra, target_variable, test_size=0.3, random_state=42)\n","\n","    # Train test split again for validation and test set\n","    X_val_extra, X_test_extra, _, _ = train_test_split(X_rest_extra, y_rest, test_size=0.5, random_state=42)\n","\n","    enc = OneHotEncoder(handle_unknown = 'ignore')\n","    enc.fit(X_train_extra)\n","    X_train_extra_enc = enc.transform(X_train_extra).toarray()\n","    X_test_extra_enc = enc.transform(X_test_extra).toarray()\n","    X_val_extra_enc = enc.transform(X_val_extra).toarray()\n","\n","\n","    trainloader = format_tensors(X_train_article, train_masks_article, X_train_title, train_masks_title, X_train_extra_enc, X_train_tweet_dtm, y_train, BATCH_SIZE)\n","    validationloader = format_tensors(X_val_article, val_masks_article, X_val_title, val_masks_title, X_val_extra_enc, X_val_tweet_dtm, y_val, BATCH_SIZE)\n","    testloader = format_tensors(X_test_article, test_masks_article, X_test_title, test_masks_title, X_test_extra_enc,X_test_tweet_dtm,  y_test, BATCH_SIZE)\n","\n","    return trainloader, validationloader, testloader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2e82a999-1f92-4175-a36d-fc6eaafd6af9","executionInfo":{"status":"ok","timestamp":1649950400625,"user_tz":-480,"elapsed":50837,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"id":"IdfqxQ6xp9X8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Title Tokenizing\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 954/954 [00:00<00:00, 1860.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Article Tokenizing\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 954/954 [00:40<00:00, 23.54it/s]\n"]}],"source":["title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, tweets_text, target_variable = tokenize(politifact_df) if article == \"politifact\" else tokenize(gossipcop_df)\n","trainloader, validationloader, testloader = train_validation_test(title_index_padded, title_mask_variable, article_index_padded, article_mask_variable, tweets_text, target_variable)"]},{"cell_type":"markdown","source":["### Model creation and test"],"metadata":{"id":"bZR5S2rppVUX"}},{"cell_type":"code","source":["model = torch.load(f\"gdrive/MyDrive/BT4222/Code/machine_learning/neil/{article}/Expt7/model_epoch4\")\n","loss_function = nn.CrossEntropyLoss()\n","model.to(device)\n","with torch.set_grad_enabled(False):\n","    model.eval()\n","    epoch_loss = 0.0\n","    loss_function = nn.CrossEntropyLoss()\n","    preds, truth, pred_proba = [],[],[]\n","    iteration = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(tqdm(testloader)):\n","            iteration += 1\n","            article_token_ids, article_masks, title_token_ids, title_masks, extra_features, tweet_text, labels = tuple(t.to(device) for t in batch)\n","            outputs = model(article_token_ids, article_masks, title_token_ids, title_masks, extra_features, tweet_text)\n","            \n","            loss = loss_function(outputs, labels)\n","            epoch_loss += float(loss.item())\n","            yhat = outputs\n","            prediction_proba = torch.sigmoid(yhat[:,1]).cpu().data.numpy()\n","            prediction = (prediction_proba > 0.5).astype(int)\n","            baseline = labels.long().cpu().data.numpy().astype(int)\n","            preds.extend(prediction)\n","            pred_proba.extend(prediction_proba)\n","            truth.extend(baseline)\n","\n","            del article_token_ids, article_masks, title_token_ids, title_masks, extra_features, tweet_text, labels #memory\n","            torch.cuda.empty_cache() #memory\n","            gc.collect() #memory\n","\n","    avg_accuracy, avg_roc_auc, avg_f1, avg_loss = accuracy_score(truth, preds), roc_auc_score(truth, pred_proba), f1_score(truth, preds), epoch_loss/float(iteration)\n","    print(f'\\nTest Accuracy: 'f'{avg_accuracy:.2f}%')\n","    print(f'Test ROC AUC: 'f'{avg_roc_auc:.2f}%')\n","    print(f'Test F1: 'f'{avg_f1:.2f}%')\n","    print(f'Test loss: 'f'{avg_loss}%\\n')\n","    test_metrics = {\n","        'accuracy':avg_accuracy,\n","        'roc_auc':avg_roc_auc,\n","        'f1':avg_f1,\n","        'loss':avg_loss\n","    }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f1942b6-12ee-4446-8b4d-a4a6351d9173","executionInfo":{"status":"ok","timestamp":1649950419101,"user_tz":-480,"elapsed":18487,"user":{"displayName":"Wang Xing Peng","userId":"13203375634952968736"}},"id":"mzTemrULpVUY"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 18/18 [00:09<00:00,  1.86it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.88%\n","Test ROC AUC: 0.93%\n","Test F1: 0.90%\n","Test loss: 0.32402483601537013%\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}